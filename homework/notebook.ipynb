{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06133ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "age",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sex",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cp",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "trestbps",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "chol",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fbs",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "restecg",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thalach",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "exang",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "oldpeak",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "slope",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ca",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "thal",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "f9c81be7-1c4f-43e2-8c95-28e7b7354ea5",
       "rows": [
        [
         "0",
         "63",
         "1",
         "1",
         "145",
         "233",
         "1",
         "2",
         "150",
         "0",
         "2.3",
         "3",
         "0",
         "fixed"
        ],
        [
         "1",
         "67",
         "1",
         "4",
         "160",
         "286",
         "0",
         "2",
         "108",
         "1",
         "1.5",
         "2",
         "3",
         "normal"
        ],
        [
         "2",
         "67",
         "1",
         "4",
         "120",
         "229",
         "0",
         "2",
         "129",
         "1",
         "2.6",
         "2",
         "2",
         "reversible"
        ],
        [
         "3",
         "37",
         "1",
         "3",
         "130",
         "250",
         "0",
         "0",
         "187",
         "0",
         "3.5",
         "3",
         "0",
         "normal"
        ],
        [
         "4",
         "41",
         "0",
         "2",
         "130",
         "204",
         "0",
         "2",
         "172",
         "0",
         "1.4",
         "1",
         "0",
         "normal"
        ],
        [
         "5",
         "56",
         "1",
         "2",
         "120",
         "236",
         "0",
         "0",
         "178",
         "0",
         "0.8",
         "1",
         "0",
         "normal"
        ],
        [
         "6",
         "62",
         "0",
         "4",
         "140",
         "268",
         "0",
         "2",
         "160",
         "0",
         "3.6",
         "3",
         "2",
         "normal"
        ],
        [
         "7",
         "57",
         "0",
         "4",
         "120",
         "354",
         "0",
         "0",
         "163",
         "1",
         "0.6",
         "1",
         "0",
         "normal"
        ],
        [
         "8",
         "63",
         "1",
         "4",
         "130",
         "254",
         "0",
         "2",
         "147",
         "0",
         "1.4",
         "2",
         "1",
         "reversible"
        ],
        [
         "9",
         "53",
         "1",
         "4",
         "140",
         "203",
         "1",
         "2",
         "155",
         "1",
         "3.1",
         "3",
         "0",
         "reversible"
        ],
        [
         "10",
         "57",
         "1",
         "4",
         "140",
         "192",
         "0",
         "0",
         "148",
         "0",
         "0.4",
         "2",
         "0",
         "fixed"
        ],
        [
         "11",
         "56",
         "0",
         "2",
         "140",
         "294",
         "0",
         "2",
         "153",
         "0",
         "1.3",
         "2",
         "0",
         "normal"
        ],
        [
         "12",
         "56",
         "1",
         "3",
         "130",
         "256",
         "1",
         "2",
         "142",
         "1",
         "0.6",
         "2",
         "1",
         "fixed"
        ],
        [
         "13",
         "44",
         "1",
         "2",
         "120",
         "263",
         "0",
         "0",
         "173",
         "0",
         "0.0",
         "1",
         "0",
         "reversible"
        ],
        [
         "14",
         "52",
         "1",
         "3",
         "172",
         "199",
         "1",
         "0",
         "162",
         "0",
         "0.5",
         "1",
         "0",
         "reversible"
        ],
        [
         "15",
         "57",
         "1",
         "3",
         "150",
         "168",
         "0",
         "0",
         "174",
         "0",
         "1.6",
         "1",
         "0",
         "normal"
        ],
        [
         "16",
         "48",
         "1",
         "2",
         "110",
         "229",
         "0",
         "0",
         "168",
         "0",
         "1.0",
         "3",
         "0",
         "reversible"
        ],
        [
         "17",
         "54",
         "1",
         "4",
         "140",
         "239",
         "0",
         "0",
         "160",
         "0",
         "1.2",
         "1",
         "0",
         "normal"
        ],
        [
         "18",
         "48",
         "0",
         "3",
         "130",
         "275",
         "0",
         "0",
         "139",
         "0",
         "0.2",
         "1",
         "0",
         "normal"
        ],
        [
         "19",
         "49",
         "1",
         "2",
         "130",
         "266",
         "0",
         "0",
         "171",
         "0",
         "0.6",
         "1",
         "0",
         "normal"
        ],
        [
         "20",
         "64",
         "1",
         "1",
         "110",
         "211",
         "0",
         "2",
         "144",
         "1",
         "1.8",
         "2",
         "0",
         "normal"
        ],
        [
         "21",
         "58",
         "0",
         "1",
         "150",
         "283",
         "1",
         "2",
         "162",
         "0",
         "1.0",
         "1",
         "0",
         "normal"
        ],
        [
         "22",
         "58",
         "1",
         "2",
         "120",
         "284",
         "0",
         "2",
         "160",
         "0",
         "1.8",
         "2",
         "0",
         "normal"
        ],
        [
         "23",
         "58",
         "1",
         "3",
         "132",
         "224",
         "0",
         "2",
         "173",
         "0",
         "3.2",
         "1",
         "2",
         "reversible"
        ],
        [
         "24",
         "60",
         "1",
         "4",
         "130",
         "206",
         "0",
         "2",
         "132",
         "1",
         "2.4",
         "2",
         "2",
         "reversible"
        ],
        [
         "25",
         "50",
         "0",
         "3",
         "120",
         "219",
         "0",
         "0",
         "158",
         "0",
         "1.6",
         "2",
         "0",
         "normal"
        ],
        [
         "26",
         "58",
         "0",
         "3",
         "120",
         "340",
         "0",
         "0",
         "172",
         "0",
         "0.0",
         "1",
         "0",
         "normal"
        ],
        [
         "27",
         "66",
         "0",
         "1",
         "150",
         "226",
         "0",
         "0",
         "114",
         "0",
         "2.6",
         "3",
         "0",
         "normal"
        ],
        [
         "28",
         "43",
         "1",
         "4",
         "150",
         "247",
         "0",
         "0",
         "171",
         "0",
         "1.5",
         "1",
         "0",
         "normal"
        ],
        [
         "29",
         "40",
         "1",
         "4",
         "110",
         "167",
         "0",
         "2",
         "114",
         "1",
         "2.0",
         "2",
         "0",
         "reversible"
        ],
        [
         "30",
         "69",
         "0",
         "1",
         "140",
         "239",
         "0",
         "0",
         "151",
         "0",
         "1.8",
         "1",
         "2",
         "normal"
        ],
        [
         "31",
         "60",
         "1",
         "4",
         "117",
         "230",
         "1",
         "0",
         "160",
         "1",
         "1.4",
         "1",
         "2",
         "reversible"
        ],
        [
         "32",
         "64",
         "1",
         "3",
         "140",
         "335",
         "0",
         "0",
         "158",
         "0",
         "0.0",
         "1",
         "0",
         "normal"
        ],
        [
         "33",
         "59",
         "1",
         "4",
         "135",
         "234",
         "0",
         "0",
         "161",
         "0",
         "0.5",
         "2",
         "0",
         "reversible"
        ],
        [
         "34",
         "44",
         "1",
         "3",
         "130",
         "233",
         "0",
         "0",
         "179",
         "1",
         "0.4",
         "1",
         "0",
         "normal"
        ],
        [
         "35",
         "42",
         "1",
         "4",
         "140",
         "226",
         "0",
         "0",
         "178",
         "0",
         "0.0",
         "1",
         "0",
         "normal"
        ],
        [
         "36",
         "43",
         "1",
         "4",
         "120",
         "177",
         "0",
         "2",
         "120",
         "1",
         "2.5",
         "2",
         "0",
         "reversible"
        ],
        [
         "37",
         "57",
         "1",
         "4",
         "150",
         "276",
         "0",
         "2",
         "112",
         "1",
         "0.6",
         "2",
         "1",
         "fixed"
        ],
        [
         "38",
         "55",
         "1",
         "4",
         "132",
         "353",
         "0",
         "0",
         "132",
         "1",
         "1.2",
         "2",
         "1",
         "reversible"
        ],
        [
         "39",
         "61",
         "1",
         "3",
         "150",
         "243",
         "1",
         "0",
         "137",
         "1",
         "1.0",
         "2",
         "0",
         "normal"
        ],
        [
         "40",
         "65",
         "0",
         "4",
         "150",
         "225",
         "0",
         "2",
         "114",
         "0",
         "1.0",
         "2",
         "3",
         "reversible"
        ],
        [
         "41",
         "65",
         "0",
         "3",
         "155",
         "269",
         "0",
         "0",
         "148",
         "0",
         "0.8",
         "1",
         "0",
         "normal"
        ],
        [
         "42",
         "67",
         "1",
         "4",
         "125",
         "254",
         "1",
         "0",
         "163",
         "0",
         "0.2",
         "2",
         "2",
         "reversible"
        ],
        [
         "43",
         "62",
         "1",
         "4",
         "120",
         "267",
         "0",
         "0",
         "99",
         "1",
         "1.8",
         "2",
         "2",
         "reversible"
        ],
        [
         "44",
         "65",
         "1",
         "4",
         "110",
         "248",
         "0",
         "2",
         "158",
         "0",
         "0.6",
         "1",
         "2",
         "fixed"
        ],
        [
         "45",
         "44",
         "1",
         "4",
         "110",
         "197",
         "0",
         "2",
         "177",
         "0",
         "0.0",
         "1",
         "1",
         "normal"
        ],
        [
         "46",
         "65",
         "0",
         "3",
         "160",
         "360",
         "0",
         "2",
         "151",
         "0",
         "0.8",
         "1",
         "0",
         "normal"
        ],
        [
         "47",
         "60",
         "1",
         "4",
         "125",
         "258",
         "0",
         "2",
         "141",
         "1",
         "2.8",
         "2",
         "1",
         "reversible"
        ],
        [
         "48",
         "51",
         "0",
         "3",
         "140",
         "308",
         "0",
         "2",
         "142",
         "0",
         "1.5",
         "1",
         "1",
         "normal"
        ],
        [
         "49",
         "48",
         "1",
         "2",
         "130",
         "245",
         "0",
         "2",
         "180",
         "0",
         "0.2",
         "2",
         "0",
         "normal"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 303
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>135</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>150</td>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>reversible</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   1       145   233    1        2      150      0      2.3   \n",
       "1     67    1   4       160   286    0        2      108      1      1.5   \n",
       "2     67    1   4       120   229    0        2      129      1      2.6   \n",
       "3     37    1   3       130   250    0        0      187      0      3.5   \n",
       "4     41    0   2       130   204    0        2      172      0      1.4   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   52    1   1       118   186    0        2      190      0      0.0   \n",
       "299   43    0   4       132   341    1        2      136      1      3.0   \n",
       "300   65    1   4       135   254    0        2      127      0      2.8   \n",
       "301   48    1   4       130   256    1        2      150      1      0.0   \n",
       "302   63    0   4       150   407    0        2      154      0      4.0   \n",
       "\n",
       "     slope  ca        thal  \n",
       "0        3   0       fixed  \n",
       "1        2   3      normal  \n",
       "2        2   2  reversible  \n",
       "3        3   0      normal  \n",
       "4        1   0      normal  \n",
       "..     ...  ..         ...  \n",
       "298      2   0       fixed  \n",
       "299      2   0  reversible  \n",
       "300      2   1  reversible  \n",
       "301      1   2  reversible  \n",
       "302      2   3  reversible  \n",
       "\n",
       "[303 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CELDA 1: FUNCIÓN DE CARGA Y PREPROCESAMIENTO DE DATOS\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Esta función se encarga de cargar y preparar el dataset de enfermedades cardíacas\n",
    "    para el análisis de machine learning.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x, y) donde x son las características y y es la variable objetivo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos pandas para manipulación de datos\n",
    "    import pandas as pd\n",
    "\n",
    "    # Cargamos el dataset desde el archivo CSV ubicado en la carpeta files/input\n",
    "    # Este dataset contiene información médica de pacientes para predecir enfermedades cardíacas\n",
    "    dataset = pd.read_csv(\"../files/input/heart_disease.csv\")\n",
    "    \n",
    "    # Extraemos la variable objetivo (target) del dataset\n",
    "    # La variable 'target' indica si el paciente tiene enfermedad cardíaca (1) o no (0)\n",
    "    # El método pop() remueve la columna del dataframe y la retorna\n",
    "    y = dataset.pop(\"target\")\n",
    "    \n",
    "    # Creamos una copia del dataset sin la variable objetivo\n",
    "    # Esto contendrá todas las características (features) que usaremos para predecir\n",
    "    x = dataset.copy()\n",
    "    \n",
    "    # Preprocesamos la variable categórica 'thal' (tipo de defecto de talio)\n",
    "    # Convertimos valores que no sean 'fixed' o 'reversible' a 'normal'\n",
    "    # Esto normaliza los datos categóricos para mejorar el rendimiento del modelo\n",
    "    x[\"thal\"] = x[\"thal\"].map(\n",
    "        lambda x: \"normal\" if x not in [\"fixed\", \"fixed\", \"reversible\"] else x\n",
    "    )\n",
    "\n",
    "    # Retornamos las características (x) y la variable objetivo (y)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Ejecutamos la función para cargar los datos y los asignamos a variables globales\n",
    "# x: DataFrame con las características de los pacientes\n",
    "# y: Serie con las etiquetas de enfermedad cardíaca (0 o 1)\n",
    "x, y = load_data()\n",
    "\n",
    "# Mostramos el DataFrame de características para inspeccionar los datos cargados\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf562d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 2: FUNCIÓN PARA DIVIDIR LOS DATOS EN ENTRENAMIENTO Y PRUEBA\n",
    "def make_train_test_split(x, y):\n",
    "    \"\"\"\n",
    "    Esta función divide el dataset en conjuntos de entrenamiento y prueba\n",
    "    para evaluar el rendimiento del modelo de manera objetiva.\n",
    "    \n",
    "    Args:\n",
    "        x: DataFrame con las características\n",
    "        y: Serie con las etiquetas objetivo\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (x_train, x_test, y_train, y_test) - conjuntos de entrenamiento y prueba\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos la función para dividir los datos\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # Dividimos los datos en entrenamiento (90%) y prueba (10%)\n",
    "    # test_size=0.10: destinamos el 10% de los datos para prueba\n",
    "    # random_state=0: fijamos la semilla aleatoria para reproducibilidad\n",
    "    # Esto asegura que siempre obtengamos la misma división de datos\n",
    "    (x_train, x_test, y_train, y_test) = train_test_split(\n",
    "        x,                    # Características de entrada\n",
    "        y,                    # Variable objetivo\n",
    "        test_size=0.10,       # 10% para prueba, 90% para entrenamiento\n",
    "        random_state=0,       # Semilla para reproducibilidad\n",
    "    )\n",
    "    \n",
    "    # Retornamos los cuatro conjuntos:\n",
    "    # x_train: características para entrenar el modelo\n",
    "    # x_test: características para evaluar el modelo\n",
    "    # y_train: etiquetas para entrenar el modelo  \n",
    "    # y_test: etiquetas para evaluar el modelo\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03d0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 3: FUNCIÓN PARA CREAR EL PIPELINE DE MACHINE LEARNING\n",
    "def make_pipeline(estimator):\n",
    "    \"\"\"\n",
    "    Esta función crea un pipeline completo de machine learning que incluye:\n",
    "    1. Transformación de variables categóricas\n",
    "    2. Selección de las mejores características\n",
    "    3. Entrenamiento del modelo\n",
    "    \n",
    "    Args:\n",
    "        estimator: El algoritmo de machine learning a usar (ej: LogisticRegression)\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: Pipeline completo listo para entrenar\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos las herramientas necesarias de scikit-learn\n",
    "    from sklearn.compose import ColumnTransformer      # Para transformar columnas específicas\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif  # Para selección de características\n",
    "    from sklearn.pipeline import Pipeline             # Para crear el pipeline\n",
    "    from sklearn.preprocessing import OneHotEncoder   # Para codificar variables categóricas\n",
    "\n",
    "    # PASO 1: TRANSFORMACIÓN DE DATOS\n",
    "    # Creamos un transformador que convierte variables categóricas a numéricas\n",
    "    transformer = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Aplicamos One-Hot Encoding a la columna 'thal' (variable categórica)\n",
    "            # One-Hot Encoding convierte categorías en columnas binarias (0 o 1)\n",
    "            # dtype=\"int\": especifica que los valores sean enteros\n",
    "            (\"ohe\", OneHotEncoder(dtype=\"int\"), [\"thal\"]),\n",
    "        ],\n",
    "        # remainder=\"passthrough\": mantiene todas las demás columnas sin modificar\n",
    "        remainder=\"passthrough\",\n",
    "    )\n",
    "\n",
    "    # PASO 2: SELECCIÓN DE CARACTERÍSTICAS\n",
    "    # SelectKBest selecciona las k mejores características basándose en un test estadístico\n",
    "    # f_classif: usa el test F de ANOVA para problemas de clasificación\n",
    "    # Esto ayuda a eliminar características irrelevantes y mejorar el rendimiento\n",
    "    selectkbest = SelectKBest(score_func=f_classif)\n",
    "\n",
    "    # PASO 3: CREACIÓN DEL PIPELINE\n",
    "    # Un pipeline ejecuta los pasos secuencialmente:\n",
    "    # 1. Transforma los datos (One-Hot Encoding)\n",
    "    # 2. Selecciona las mejores características\n",
    "    # 3. Entrena el modelo con las características seleccionadas\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"tranformer\", transformer),    # Transformación de datos categóricos\n",
    "            (\"selectkbest\", selectkbest),   # Selección de mejores características\n",
    "            (\"estimator\", estimator),       # Algoritmo de machine learning\n",
    "        ],\n",
    "        verbose=False,  # No mostrar información detallada durante la ejecución\n",
    "    )\n",
    "\n",
    "    # Retornamos el pipeline completo listo para usar\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b68d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 4: FUNCIÓN PARA BÚSQUEDA DE HIPERPARÁMETROS ÓPTIMOS\n",
    "def make_grid_search(estimator, param_grid, cv=5):\n",
    "    \"\"\"\n",
    "    Esta función implementa Grid Search para encontrar automáticamente \n",
    "    la mejor combinación de hiperparámetros para el modelo.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo/pipeline a optimizar\n",
    "        param_grid: Diccionario con los parámetros a probar\n",
    "        cv: Número de folds para validación cruzada (por defecto 5)\n",
    "    \n",
    "    Returns:\n",
    "        GridSearchCV: Objeto configurado para búsqueda de hiperparámetros\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos GridSearchCV para búsqueda exhaustiva de hiperparámetros\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # CONFIGURACIÓN DE GRID SEARCH\n",
    "    # GridSearchCV prueba todas las combinaciones posibles de parámetros\n",
    "    # y encuentra la que produce el mejor rendimiento usando validación cruzada\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,              # El pipeline/modelo a optimizar\n",
    "        param_grid=param_grid,            # Diccionario con parámetros a probar\n",
    "        cv=cv,                           # Validación cruzada de 5 folds por defecto\n",
    "        scoring=\"balanced_accuracy\",      # Métrica de evaluación (accuracy balanceada)\n",
    "    )\n",
    "    \n",
    "    # EXPLICACIÓN DE PARÁMETROS:\n",
    "    # - estimator: El pipeline que queremos optimizar\n",
    "    # - param_grid: Define qué valores probar para cada parámetro\n",
    "    # - cv=5: Divide los datos en 5 partes, entrena en 4 y valida en 1, repite 5 veces\n",
    "    # - scoring=\"balanced_accuracy\": Usa accuracy balanceada (mejor para clases desbalanceadas)\n",
    "\n",
    "    # Retornamos el objeto GridSearch configurado (aún no ejecutado)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457de8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 5: FUNCIÓN PARA GUARDAR EL MODELO ENTRENADO\n",
    "def save_estimator(estimator):\n",
    "    \"\"\"\n",
    "    Esta función guarda el modelo entrenado en un archivo usando serialización.\n",
    "    Esto permite reutilizar el modelo sin necesidad de entrenarlo nuevamente.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo entrenado que queremos guardar\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos pickle para serialización de objetos Python\n",
    "    # Pickle convierte objetos Python en bytes para almacenarlos en archivos\n",
    "    import pickle\n",
    "\n",
    "    # PROCESO DE GUARDADO:\n",
    "    # Abrimos un archivo en modo binario de escritura (\"wb\")\n",
    "    # \"estimator.pickle\" será el nombre del archivo donde se guarda el modelo\n",
    "    with open(\"estimator.pickle\", \"wb\") as file:\n",
    "        # pickle.dump() serializa el objeto estimator y lo guarda en el archivo\n",
    "        # Esto preserva completamente el estado del modelo entrenado:\n",
    "        # - Pesos y parámetros aprendidos\n",
    "        # - Configuración de hiperparámetros\n",
    "        # - Transformaciones aplicadas a los datos\n",
    "        pickle.dump(estimator, file)\n",
    "    \n",
    "    # Al salir del bloque 'with', el archivo se cierra automáticamente\n",
    "    # El modelo queda guardado y puede ser cargado posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbbdd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_estimator():\n",
    "    \"\"\"\n",
    "    Esta función carga un modelo previamente guardado desde el archivo.\n",
    "    Si no existe un modelo guardado, retorna None.\n",
    "    \n",
    "    Returns:\n",
    "        object or None: El modelo cargado o None si no existe archivo\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos las librerías necesarias\n",
    "    import os      # Para verificar si existe el archivo\n",
    "    import pickle  # Para deserializar el objeto guardado\n",
    "\n",
    "    # VERIFICACIÓN DE EXISTENCIA DEL ARCHIVO\n",
    "    # Verificamos si existe el archivo \"estimator.pickle\"\n",
    "    # Si no existe, significa que no hay un modelo previamente guardado\n",
    "    if not os.path.exists(\"estimator.pickle\"):\n",
    "        return None  # Retornamos None si no hay modelo guardado\n",
    "    \n",
    "    # PROCESO DE CARGA:\n",
    "    # Si el archivo existe, lo abrimos en modo binario de lectura (\"rb\")\n",
    "    with open(\"estimator.pickle\", \"rb\") as file:\n",
    "        # pickle.load() deserializa el objeto desde el archivo\n",
    "        # Esto restaura completamente el modelo con:\n",
    "        # - Todos los pesos y parámetros entrenados\n",
    "        # - La configuración de hiperparámetros\n",
    "        # - Las transformaciones de datos configuradas\n",
    "        estimator = pickle.load(file)\n",
    "\n",
    "    # Retornamos el modelo cargado, listo para hacer predicciones\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd4bbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 7: FUNCIÓN PRINCIPAL DE ENTRENAMIENTO CON COMPARACIÓN DE MODELOS\n",
    "def train_estimator(estimator):\n",
    "    \"\"\"\n",
    "    Esta función entrena un modelo y lo compara con un modelo previamente guardado.\n",
    "    Solo guarda el nuevo modelo si es mejor que el anterior.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo a entrenar y evaluar\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos las librerías necesarias\n",
    "    from sklearn.linear_model import LinearRegression  # (No se usa en este contexto)\n",
    "    from sklearn.metrics import mean_absolute_error    # Para calcular error absoluto medio\n",
    "\n",
    "    # PASO 1: PREPARACIÓN DE DATOS\n",
    "    # Cargamos los datos usando la función definida anteriormente\n",
    "    data, target = load_data()\n",
    "\n",
    "    # Dividimos los datos en conjuntos de entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = make_train_test_split(\n",
    "        x=data,      # Características\n",
    "        y=target,    # Variable objetivo\n",
    "    )\n",
    "\n",
    "    # PASO 2: ENTRENAMIENTO DEL NUEVO MODELO\n",
    "    # Entrenamos el estimador con los datos de entrenamiento\n",
    "    # fit() ajusta los parámetros del modelo a los datos\n",
    "    estimator.fit(x_train, y_train)\n",
    "\n",
    "    # PASO 3: COMPARACIÓN CON MODELO ANTERIOR (SI EXISTE)\n",
    "    # Intentamos cargar un modelo previamente guardado\n",
    "    best_estimator = load_estimator()\n",
    "\n",
    "    # Si existe un modelo anterior, comparamos su rendimiento\n",
    "    if best_estimator is not None:\n",
    "\n",
    "        # Calculamos el error del modelo guardado anteriormente\n",
    "        # mean_absolute_error mide la diferencia promedio entre predicciones y valores reales\n",
    "        saved_mae = mean_absolute_error(\n",
    "            y_true=y_test,                              # Valores reales de prueba\n",
    "            y_pred=best_estimator.predict(x_test)       # Predicciones del modelo guardado\n",
    "        )\n",
    "\n",
    "        # Calculamos el error del modelo actual recién entrenado\n",
    "        current_mae = mean_absolute_error(\n",
    "            y_true=y_test,                       # Valores reales de prueba\n",
    "            y_pred=estimator.predict(x_test)     # Predicciones del modelo actual\n",
    "        )\n",
    "\n",
    "        # DECISIÓN: ¿Cuál modelo es mejor?\n",
    "        # Si el modelo guardado tiene menor error, lo mantenemos\n",
    "        # Solo reemplazamos si el nuevo modelo es mejor\n",
    "        if saved_mae < current_mae:\n",
    "            estimator = best_estimator  # Mantenemos el modelo anterior (mejor)\n",
    "\n",
    "    # PASO 4: GUARDAR EL MEJOR MODELO\n",
    "    # Guardamos el modelo (ya sea el nuevo si es mejor, o el anterior si era mejor)\n",
    "    save_estimator(estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6001f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELDA 8: ENTRENAMIENTO DE REGRESIÓN LOGÍSTICA CON OPTIMIZACIÓN DE HIPERPARÁMETROS\n",
    "def train_logistic_regression():\n",
    "    \"\"\"\n",
    "    Esta función configura y entrena un modelo de Regresión Logística\n",
    "    con búsqueda automática de los mejores hiperparámetros.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos el algoritmo de Regresión Logística\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    # PASO 1: CREACIÓN DEL PIPELINE\n",
    "    # Creamos un pipeline completo que incluye:\n",
    "    # - Transformación de datos categóricos\n",
    "    # - Selección de características\n",
    "    # - Modelo de Regresión Logística\n",
    "    pipeline = make_pipeline(\n",
    "        estimator=LogisticRegression(\n",
    "            max_iter=10000,    # Máximo 10,000 iteraciones para convergencia\n",
    "            solver=\"saga\"      # Algoritmo 'saga' que soporta regularización L1 y L2\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # PASO 2: DEFINICIÓN DEL ESPACIO DE BÚSQUEDA DE HIPERPARÁMETROS\n",
    "    # param_grid define todos los valores que queremos probar para cada parámetro\n",
    "    param_grid = {\n",
    "        # Número de características a seleccionar (de 1 a 10)\n",
    "        \"selectkbest__k\": range(1, 11),\n",
    "        \n",
    "        # Tipo de regularización:\n",
    "        # - \"l1\": Lasso (elimina características irrelevantes)\n",
    "        # - \"l2\": Ridge (reduce magnitud de coeficientes)\n",
    "        \"estimator__penalty\": [\"l1\", \"l2\"],\n",
    "        \n",
    "        # Fuerza de regularización (parámetro C):\n",
    "        # - Valores pequeños (0.001): alta regularización\n",
    "        # - Valores grandes (100): baja regularización\n",
    "        \"estimator__C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    }\n",
    "    \n",
    "    # TOTAL DE COMBINACIONES A PROBAR:\n",
    "    # 10 valores de k × 2 tipos de penalty × 6 valores de C = 120 combinaciones\n",
    "\n",
    "    # PASO 3: CONFIGURACIÓN DE GRID SEARCH\n",
    "    # Creamos el objeto que probará todas las combinaciones\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline,        # Pipeline a optimizar\n",
    "        param_grid=param_grid,     # Parámetros a probar\n",
    "        cv=5,                     # Validación cruzada de 5 folds\n",
    "    )\n",
    "\n",
    "    # PASO 4: ENTRENAMIENTO Y EVALUACIÓN\n",
    "    # Entrenamos el modelo con búsqueda de hiperparámetros\n",
    "    # Esta función también compara con modelos anteriores\n",
    "    train_estimator(estimator)\n",
    "\n",
    "\n",
    "# EJECUCIÓN: Entrenamos el modelo de Regresión Logística\n",
    "train_logistic_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33c929c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(\n",
    "    y_train_true,    # Etiquetas reales del conjunto de entrenamiento\n",
    "    y_test_true,     # Etiquetas reales del conjunto de prueba\n",
    "    y_train_pred,    # Predicciones del modelo en entrenamiento\n",
    "    y_test_pred,     # Predicciones del modelo en prueba\n",
    "):\n",
    "    \"\"\"\n",
    "    Esta función calcula métricas de rendimiento para evaluar la calidad\n",
    "    del modelo tanto en entrenamiento como en prueba.\n",
    "    \n",
    "    Args:\n",
    "        y_train_true: Etiquetas verdaderas de entrenamiento\n",
    "        y_test_true: Etiquetas verdaderas de prueba  \n",
    "        y_train_pred: Predicciones en entrenamiento\n",
    "        y_test_pred: Predicciones en prueba\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (accuracy_train, accuracy_test, balanced_accuracy_train, balanced_accuracy_test)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos las métricas de evaluación de scikit-learn\n",
    "    from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "    # MÉTRICA 1: ACCURACY (EXACTITUD) \n",
    "    # Mide el porcentaje de predicciones correctas\n",
    "    # Fórmula: (Predicciones correctas) / (Total de predicciones)\n",
    "    \n",
    "    # Accuracy en entrenamiento\n",
    "    accuracy_train = round(accuracy_score(y_train_true, y_train_pred), 4)\n",
    "    \n",
    "    # Accuracy en prueba (el más importante para evaluar generalización)\n",
    "    accuracy_test = round(accuracy_score(y_test_true, y_test_pred), 4)\n",
    "    \n",
    "    # MÉTRICA 2: BALANCED ACCURACY (EXACTITUD BALANCEADA)\n",
    "    # Mejor métrica para datasets con clases desbalanceadas\n",
    "    # Promedia la sensibilidad (recall) de cada clase\n",
    "    # Es más robusta cuando hay diferentes cantidades de ejemplos por clase\n",
    "    \n",
    "    # Balanced accuracy en entrenamiento\n",
    "    balanced_accuracy_train = round(\n",
    "        balanced_accuracy_score(y_train_true, y_train_pred), 4\n",
    "    )\n",
    "    \n",
    "    # Balanced accuracy en prueba\n",
    "    balanced_accuracy_test = round(balanced_accuracy_score(y_test_true, y_test_pred), 4)\n",
    "\n",
    "    # INTERPRETACIÓN DE RESULTADOS:\n",
    "    # - Si accuracy_train >> accuracy_test: posible sobreajuste (overfitting)\n",
    "    # - Si ambas son similares: buen equilibrio bias-varianza\n",
    "    # - Balanced accuracy es más confiable en problemas de clasificación médica\n",
    "    \n",
    "    # Retornamos las cuatro métricas calculadas\n",
    "    return (\n",
    "        accuracy_train,\n",
    "        accuracy_test,\n",
    "        balanced_accuracy_train,\n",
    "        balanced_accuracy_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c00cb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(\n",
    "    estimator,                 # El modelo entrenado\n",
    "    accuracy_train,           # Accuracy en entrenamiento\n",
    "    accuracy_test,            # Accuracy en prueba\n",
    "    balanced_accuracy_train,  # Balanced accuracy en entrenamiento\n",
    "    balanced_accuracy_test,   # Balanced accuracy en prueba\n",
    "):\n",
    "    \"\"\"\n",
    "    Esta función genera un reporte visual del rendimiento del modelo\n",
    "    mostrando las métricas de evaluación de forma organizada.\n",
    "    \n",
    "    Args:\n",
    "        estimator: El modelo entrenado para mostrar su información\n",
    "        accuracy_train: Exactitud en datos de entrenamiento\n",
    "        accuracy_test: Exactitud en datos de prueba\n",
    "        balanced_accuracy_train: Exactitud balanceada en entrenamiento\n",
    "        balanced_accuracy_test: Exactitud balanceada en prueba\n",
    "    \"\"\"\n",
    "    \n",
    "    # FORMATO DEL REPORTE:\n",
    "    \n",
    "    # Línea 1: Muestra información del estimador (tipo de modelo y parámetros)\n",
    "    print(estimator, \":\", sep=\"\")\n",
    "    \n",
    "    # Línea 2: Separador visual de 80 caracteres para mejorar legibilidad\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Línea 3: Muestra Balanced Accuracy (métrica principal)\n",
    "    # Formato: \"Métrica: valor_prueba (valor_entrenamiento)\"\n",
    "    # El valor de prueba aparece primero porque es el más importante\n",
    "    print(f\"Balanced Accuracy: {balanced_accuracy_test} ({balanced_accuracy_train})\")\n",
    "    \n",
    "    # Línea 4: Muestra Accuracy tradicional como métrica secundaria\n",
    "    # Misma estructura: prueba primero, entrenamiento entre paréntesis\n",
    "    print(f\"         Accuracy: {accuracy_test} ({accuracy_train})\")\n",
    "    \n",
    "    # INTERPRETACIÓN DEL FORMATO:\n",
    "    # - El valor sin paréntesis es el rendimiento en datos NO VISTOS (prueba)\n",
    "    # - El valor entre paréntesis es el rendimiento en datos de entrenamiento\n",
    "    # - Si hay gran diferencia, puede indicar sobreajuste\n",
    "    # - Balanced Accuracy se muestra primero por ser más robusta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8536612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tranformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('ohe',\n",
      "                                                  OneHotEncoder(dtype='int'),\n",
      "                                                  ['thal'])])),\n",
      "                ('selectkbest', SelectKBest(k=6)),\n",
      "                ('estimator',\n",
      "                 LogisticRegression(C=10, max_iter=10000, penalty='l1',\n",
      "                                    solver='saga'))]):\n",
      "--------------------------------------------------------------------------------\n",
      "Balanced Accuracy: 0.6368 (0.8296)\n",
      "         Accuracy: 0.6774 (0.8787)\n"
     ]
    }
   ],
   "source": [
    "def check_estimator():\n",
    "    \"\"\"\n",
    "    Esta función carga el mejor modelo guardado y evalúa su rendimiento\n",
    "    en los conjuntos de entrenamiento y prueba, mostrando un reporte completo.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos las librerías necesarias\n",
    "    import pickle                                                    # Para cargar modelo\n",
    "    import pandas as pd                                             # Para manipulación de datos\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score  # Métricas (no usadas aquí)\n",
    "\n",
    "    # PASO 1: PREPARACIÓN DE DATOS\n",
    "    # Cargamos el mismo dataset usado para entrenamiento\n",
    "    data, target = load_data()\n",
    "\n",
    "    # Creamos la misma división entrenamiento/prueba\n",
    "    # IMPORTANTE: Usar la misma división para comparación justa\n",
    "    x_train, x_test, y_train_true, y_test_true = make_train_test_split(\n",
    "        x=data,      # Características\n",
    "        y=target,    # Variable objetivo\n",
    "    )\n",
    "\n",
    "    # PASO 2: CARGA DEL MEJOR MODELO\n",
    "    # Cargamos el modelo que fue guardado como el mejor\n",
    "    # Este modelo ya tiene los hiperparámetros optimizados\n",
    "    estimator = load_estimator()\n",
    "\n",
    "    # PASO 3: GENERACIÓN DE PREDICCIONES\n",
    "    # Hacemos predicciones en ambos conjuntos de datos\n",
    "    \n",
    "    # Predicciones en datos de entrenamiento\n",
    "    # Útil para detectar sobreajuste si la diferencia con prueba es muy grande\n",
    "    y_train_pred = estimator.predict(x_train)\n",
    "    \n",
    "    # Predicciones en datos de prueba\n",
    "    # Esta es la métrica más importante: rendimiento en datos no vistos\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "\n",
    "    # PASO 4: CÁLCULO DE MÉTRICAS\n",
    "    # Calculamos todas las métricas de evaluación\n",
    "    (\n",
    "        accuracy_train,           # Exactitud en entrenamiento\n",
    "        accuracy_test,            # Exactitud en prueba\n",
    "        balanced_accuracy_train,  # Exactitud balanceada en entrenamiento\n",
    "        balanced_accuracy_test,   # Exactitud balanceada en prueba\n",
    "    ) = eval_metrics(\n",
    "        y_train_true,    # Etiquetas reales de entrenamiento\n",
    "        y_test_true,     # Etiquetas reales de prueba\n",
    "        y_train_pred,    # Predicciones en entrenamiento\n",
    "        y_test_pred,     # Predicciones en prueba\n",
    "    )\n",
    "\n",
    "    # PASO 5: MOSTRAR REPORTE\n",
    "    # Generamos un reporte visual con el rendimiento del modelo\n",
    "    # estimator.best_estimator_ contiene el modelo con mejores hiperparámetros\n",
    "    report(\n",
    "        estimator.best_estimator_,    # Información del mejor modelo encontrado\n",
    "        accuracy_train,               # Métricas de entrenamiento\n",
    "        accuracy_test,                # Métricas de prueba\n",
    "        balanced_accuracy_train,\n",
    "        balanced_accuracy_test,\n",
    "    )\n",
    "\n",
    "\n",
    "# EJECUCIÓN: Evaluamos el modelo guardado\n",
    "check_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19c9a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Samuel Castaño\\Desktop\\Fundamentos Analtica 2025-1\\Clases\\Clase 10\\PRE-23-selectkbest-para-clasificacion-SamuCasta\\.venv\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:787: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# CELDA 12: ENTRENAMIENTO DE RED NEURONAL (MLP) CON OPTIMIZACIÓN DE HIPERPARÁMETROS\n",
    "def train_mlp_classifier():\n",
    "    \"\"\"\n",
    "    Esta función configura y entrena un Perceptrón Multicapa (MLP)\n",
    "    con búsqueda automática de los mejores hiperparámetros.\n",
    "    MLP es una red neuronal artificial para problemas de clasificación.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Importamos el algoritmo de Red Neuronal (Multi-Layer Perceptron)\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    # PASO 1: CREACIÓN DEL PIPELINE\n",
    "    # Creamos un pipeline que incluye el preprocesamiento y la red neuronal\n",
    "    pipeline = make_pipeline(\n",
    "        estimator=MLPClassifier(\n",
    "            max_iter=10000,    # Máximo 10,000 iteraciones para entrenamiento\n",
    "                              # Las redes neuronales necesitan más iteraciones que otros algoritmos\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # PASO 2: DEFINICIÓN DEL ESPACIO DE BÚSQUEDA DE HIPERPARÁMETROS\n",
    "    # Para redes neuronales, optimizamos:\n",
    "    param_grid = {\n",
    "        # Número de características a seleccionar (igual que antes)\n",
    "        \"selectkbest__k\": range(1, 11),\n",
    "        \n",
    "        # ARQUITECTURA DE LA RED NEURONAL:\n",
    "        # hidden_layer_sizes define cuántas neuronas tiene la capa oculta\n",
    "        # (h,) significa una sola capa oculta con h neuronas\n",
    "        # Probamos desde 1 hasta 10 neuronas en la capa oculta\n",
    "        \"estimator__hidden_layer_sizes\": [(h,) for h in range(1, 11)],\n",
    "        \n",
    "        # TASA DE APRENDIZAJE:\n",
    "        # learning_rate_init controla qué tan rápido aprende la red\n",
    "        # - Valores pequeños (0.0001): aprendizaje lento pero estable\n",
    "        # - Valores grandes (1.0): aprendizaje rápido pero puede ser inestable\n",
    "        \"estimator__learning_rate_init\": [0.0001, 0.001, 0.01, 0.1, 1.0],\n",
    "    }\n",
    "    \n",
    "    # TOTAL DE COMBINACIONES A PROBAR:\n",
    "    # 10 valores de k × 10 arquitecturas × 5 tasas de aprendizaje = 500 combinaciones\n",
    "    # Esto es computacionalmente más costoso que la regresión logística\n",
    "\n",
    "    # PASO 3: CONFIGURACIÓN DE GRID SEARCH\n",
    "    # Creamos el objeto que probará todas las combinaciones\n",
    "    estimator = make_grid_search(\n",
    "        estimator=pipeline,        # Pipeline con red neuronal\n",
    "        param_grid=param_grid,     # Parámetros específicos de MLP\n",
    "        cv=5,                     # Validación cruzada de 5 folds\n",
    "    )\n",
    "\n",
    "    # PASO 4: ENTRENAMIENTO Y COMPARACIÓN\n",
    "    # Entrenamos la red neuronal y la comparamos con modelos anteriores\n",
    "    # Si la red neuronal es mejor, reemplazará al modelo guardado\n",
    "    train_estimator(estimator)\n",
    "\n",
    "\n",
    "# EJECUCIÓN DEL EXPERIMENTO COMPLETO:\n",
    "\n",
    "# 1. Entrenamos la red neuronal con optimización de hiperparámetros\n",
    "train_mlp_classifier()\n",
    "\n",
    "# 2. Evaluamos inmediatamente el mejor modelo (puede ser MLP o el anterior)\n",
    "# Esto nos permite comparar si la red neuronal mejoró el rendimiento\n",
    "check_estimator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
